{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz = np.load('Audiobooks_data_train.npz')\n",
    "train_inputs, train_targets = npz['inputs'].astype(float), npz['targets'].astype(int)\n",
    "\n",
    "npz = np.load('Audiobooks_data_validation.npz')\n",
    "validation_inputs, validation_targets = npz['inputs'].astype(float), npz['targets'].astype(int)\n",
    "\n",
    "npz = np.load('Audiobooks_data_test.npz')\n",
    "test_inputs, test_targets = npz['inputs'].astype(float), npz['targets'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(name, history):\n",
    "  plt.title(name +' - '+ 'Train vs Validation Losses')\n",
    "  train_losses = history.history['loss']\n",
    "  val_losses = history.history['val_loss']\n",
    "  plt.plot(train_losses,'-o')\n",
    "  plt.plot(val_losses,'-o')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.ylabel('Losses')\n",
    "  plt.legend(['Train Losses','Validation Losses'])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs=100, batch_size=9, optimizer=\"adam\", sequential= [], patience = 2):\n",
    "  model = tf.keras.Sequential(sequential)\n",
    "  model.compile(optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
    "  history = model.fit(train_inputs,train_targets, \n",
    "            batch_size= batch_size, epochs = epochs,\n",
    "            callbacks= [tf.keras.callbacks.EarlyStopping(patience =patience)],\n",
    "            validation_data=(validation_inputs, validation_targets),\n",
    "            validation_steps=10,\n",
    "            verbose = 0\n",
    "          )\n",
    "  test_loss, test_accuracy = model.evaluate(test_inputs, test_targets)\n",
    "  return test_loss, test_accuracy , history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 10\n",
    "output_size = 2\n",
    "hidden_nodes = 8\n",
    "sequential = []\n",
    "for i in range(3):\n",
    "  sequential.append(tf.keras.layers.Dense(hidden_nodes, activation='relu'))\n",
    "sequential.append(tf.keras.layers.Dense(output_size, activation='softmax'))\n",
    "test_loss, test_accuracy, history = train(epochs=100, batch_size=9, optimizer=\"adam\", \n",
    "                                          sequential= sequential, patience = 2)\n",
    "print('\\nTest loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))\n",
    "plot_loss(\"\", history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "14/14 [==============================] - 0s 2ms/step - loss: 0.1885 - accuracy: 0.9442\n",
    "\n",
    "Test loss: 0.19. Test accuracy: 94.42%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_size = 10\n",
    "output_size = 2\n",
    "hidden_nodes = 8\n",
    "sequential = []\n",
    "for i in range(2):\n",
    "  sequential.append(tf.keras.layers.Dense(hidden_nodes, activation='relu'))\n",
    "sequential.append(tf.keras.layers.Dense(output_size, activation='softmax'))\n",
    "\n",
    "# \"Adagrad\",\"Adadelta\",\"Adam\",\"Adamax\",\"SGD\",\"Nadam\",\"RMSprop\",\"FTRL\"\n",
    "optimizers = [\"Adagrad\",\"Adadelta\",\"Adam\",\"Adamax\",\"SGD\",\"RMSprop\"]\n",
    "histories = []\n",
    "test_accuracies = []\n",
    "for i, opt in enumerate(optimizers):\n",
    "  test_loss, test_accuracy, history = train(epochs=100, batch_size=9, optimizer=optimizers[i], \n",
    "                                          sequential= sequential, patience = 1)\n",
    "  print(\"Optimizers:\"+ optimizers[i])\n",
    "  print('\\nTest loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))\n",
    "  histories.append(history)\n",
    "  test_accuracies.append(test_accuracy)\n",
    "  plot_loss(optimizers[i],history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Adagrad\",\"Adadelta\",\"Adam\",\"Adamax\",\"SGD\",\"Nadam\",\"RMSprop\",\"FTRL\"\n",
    "# optimizers = [\"Adagrad\",\"Adadelta\",\"Adam\",\"Adamax\",\"SGD\",\"RMSprop\"]\n",
    "# histories = []\n",
    "# test_accuracies = []\n",
    "# for i, opt in enumerate(optimizers):\n",
    "#   test_loss, test_accuracy, history = train(epochs=100, batch_size=9, optimizer=opt, sequential= sequential, patience = 5)\n",
    "#   print(\"Optimizers:\"+ optimizers[i])\n",
    "#   print('\\nTest loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))\n",
    "#   histories.append(history)\n",
    "#   test_accuracies.append(test_accuracy)\n",
    "#   plot_loss(optimizers[i],history)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
